<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <title>WebGPU Post Processing - Step 1 - No-op</title>
    <style>
      @import url(resources/webgpu-lesson.css);
html, body {
  margin: 0;       /* remove the default margin          */
  height: 100%;    /* make the html,body fill the page   */
}
canvas {
  display: block;  /* make the canvas act like a block   */
  width: 100%;     /* make the canvas fill its container */
  height: 100%;
}
    </style>
  </head>
  <body>
    <canvas></canvas>
  </body>
  <script type="module">
import GUI from '../3rdparty/muigui-0.x.module.js';
// see https://webgpufundamentals.org/webgpu/lessons/webgpu-utils.html#webgpu-utils
import {createTextureFromImage} from '../3rdparty/webgpu-utils-1.x.module.js';
// see https://webgpufundamentals.org/webgpu/lessons/webgpu-matrix-math.html
import {mat4} from '../3rdparty/wgpu-matrix.module.js';

import * as lutParser from './resources/js/lut-reader.js';
import * as dragAndDrop from './resources/js/drag-and-drop.js';

const lutTextures = [
  { name: 'identity',           size: 2, filter: true , },
  { name: 'identity no filter', size: 2, filter: false, },
  { name: 'monochrome',      url: 'resources/images/lut/monochrome-s8.png' }, /* webgpufundamentals: url */
  { name: 'sepia',           url: 'resources/images/lut/sepia-s8.png' }, /* webgpufundamentals: url */
  { name: 'saturated',       url: 'resources/images/lut/saturated-s8.png', }, /* webgpufundamentals: url */
  { name: 'posterize',       url: 'resources/images/lut/posterize-s8n.png', }, /* webgpufundamentals: url */
  { name: 'posterize-3-rgb', url: 'resources/images/lut/posterize-3-rgb-s8n.png', }, /* webgpufundamentals: url */
  { name: 'posterize-3-lab', url: 'resources/images/lut/posterize-3-lab-s8n.png', }, /* webgpufundamentals: url */
  { name: 'posterize-4-lab', url: 'resources/images/lut/posterize-4-lab-s8n.png', }, /* webgpufundamentals: url */
  { name: 'posterize-more',  url: 'resources/images/lut/posterize-more-s8n.png', }, /* webgpufundamentals: url */
  { name: 'inverse',         url: 'resources/images/lut/inverse-s8.png', }, /* webgpufundamentals: url */
  { name: 'color negative',  url: 'resources/images/lut/color-negative-s8.png', }, /* webgpufundamentals: url */
  { name: 'high contrast',   url: 'resources/images/lut/high-contrast-bw-s8.png', }, /* webgpufundamentals: url */
  { name: 'funky contrast',  url: 'resources/images/lut/funky-contrast-s8.png', }, /* webgpufundamentals: url */
  { name: 'nightvision',     url: 'resources/images/lut/nightvision-s8.png', }, /* webgpufundamentals: url */
  { name: 'thermal',         url: 'resources/images/lut/thermal-s8.png', }, /* webgpufundamentals: url */
  { name: 'b/w',             url: 'resources/images/lut/black-white-s8n.png', }, /* webgpufundamentals: url */
  { name: 'hue +60',         url: 'resources/images/lut/hue-plus-60-s8.png', }, /* webgpufundamentals: url */
  { name: 'hue +180',        url: 'resources/images/lut/hue-plus-180-s8.png', }, /* webgpufundamentals: url */
  { name: 'hue -60',         url: 'resources/images/lut/hue-minus-60-s8.png', }, /* webgpufundamentals: url */
  { name: 'red to cyan',     url: 'resources/images/lut/red-to-cyan-s8.png' }, /* webgpufundamentals: url */
  { name: 'blues',           url: 'resources/images/lut/blues-s8.png' }, /* webgpufundamentals: url */
  { name: 'infrared',        url: 'resources/images/lut/infrared-s8.png' }, /* webgpufundamentals: url */
  { name: 'radioactive',     url: 'resources/images/lut/radioactive-s8.png' }, /* webgpufundamentals: url */
  { name: 'goolgey',         url: 'resources/images/lut/googley-s8.png' }, /* webgpufundamentals: url */
  { name: 'bgy',             url: 'resources/images/lut/bgy-s8.png' }, /* webgpufundamentals: url */
];

function makeIdentityLutTexture(device) {
  const texture = device.createTexture({
    size: [2, 2, 2],
    dimension: '3d',
    format: 'rgba8unorm',
    usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST,
  });

  const identityLUT = new Uint8Array([
      0,   0,   0, 255,  // black
    255,   0,   0, 255,  // red
      0, 255,   0, 255,  // green
    255, 255,   0, 255,  // yellow
      0,   0, 255, 255,  // blue
    255,   0, 255, 255,  // magenta
      0, 255, 255, 255,  // cyan
    255, 255, 255, 255,  // white
  ]);

  device.queue.writeTexture(
    { texture },
    identityLUT,
    { bytesPerRow: 8, rowsPerImage: 2},
    [2, 2, 2],
  );

  return texture;
}

/**
 * create a LUT texture from an image URL. You must pass in the size of the LUT
 * It's assumed to be in the top left corner of the image.
 *
 * +---------+---------+---------+---------+---------+---------+---→
 * |         |         |         |         |         |         |
 * | layer 0 | layer 1 | layer 2 | layer 3 |   ...   | layer n |
 * |         |         |         |         |         |         |
 * +---------+---------+---------+---------+---------+---------+
 * |
 * ↓
 */
const createLUTTextureFromImage = (function() {
  const ctx = document.createElement('canvas').getContext('2d', { willReadFrequently: true });

  return async function createLUTTextureFromImage(device, url, lutSize) {
    const img = new Image();
    img.src = url;
    await img.decode();
    ctx.canvas.width = img.width;
    ctx.canvas.height = img.height;
    ctx.drawImage(img, 0, 0);
    const imgData = ctx.getImageData(0, 0, lutSize * lutSize, lutSize);

    const texture = device.createTexture({
      size: [lutSize, lutSize, lutSize],
      dimension: '3d',
      format: 'rgba8unorm',
      usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST,
    });

    for (let z = 0; z < lutSize; ++z) {
      device.queue.writeTexture(
        { texture, origin: [0, 0, z] },
        imgData.data,
        { offset: lutSize * 4, bytesPerRow: imgData.width * 4 },
        [lutSize, lutSize],
      );
    }
    return texture;
  };
})();


async function main() {
  const adapter = await navigator.gpu?.requestAdapter();
  const device = await adapter?.requestDevice();
  if (!device) {
    fail('need a browser that supports WebGPU');
    return;
  }

  const identityLUTTexture = makeIdentityLutTexture(device);
  await Promise.all(lutTextures.map((info) => {
    // if not size set get it from the filename
    if (!info.size) {
      // assumes filename ends in '-s<num>[n]'
      // where <num> is the size of the 3DLUT cube
      // and [n] means 'no filtering' or 'nearest'
      //
      // examples:
      //    'foo-s16.png' = size:16, filter: true
      //    'bar-s8n.png' = size:8, filter: false
      const m = /-s(\d+)(n*)\.[^.]+$/.exec(info.url);
      if (m) {
        info.size = parseInt(m[1]);
        info.filter = info.filter === undefined ? m[2] !== 'n' : info.filter;
      }
    }

    if (info.url) {
      return createLUTTextureFromImage(device, info.url, info.size)
        .then(texture => {
          info.texture = texture;
        });
    } else {
      info.texture = identityLUTTexture;
      return Promise.resolve();
    }
  }));

  // Get a WebGPU context from the canvas and configure it
  const canvas = document.querySelector('canvas');
  const context = canvas.getContext('webgpu');
  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
  context.configure({
    device,
    format: presentationFormat,
  });

  const module = device.createShaderModule({
    code: `
      struct VSOutput {
        @builtin(position) position: vec4f,
        @location(0) texcoord: vec2f,
      };

      struct Uniforms {
        matrix: mat4x4f,
      };

      @group(0) @binding(0) var<uniform> uni: Uniforms;
      @group(0) @binding(1) var tex: texture_2d<f32>;
      @group(0) @binding(2) var smp: sampler;

      @vertex fn vs(@builtin(vertex_index) vNdx: u32) -> VSOutput {
        let positions = array(
          vec2f( 0,  0),
          vec2f( 1,  0),
          vec2f( 0,  1),
          vec2f( 0,  1),
          vec2f( 1,  0),
          vec2f( 1,  1),
        );
        let pos = positions[vNdx];
        return VSOutput(
          uni.matrix * vec4f(pos, 0, 1),
          pos,
        );
      }

      @fragment fn fs(fsInput: VSOutput) -> @location(0) vec4f {
        return textureSample(tex, smp, fsInput.texcoord);
      }
    `,
  });

  const pipeline = device.createRenderPipeline({
    label: 'textured unit quad',
    layout: 'auto',
    vertex: {
      module,
    },
    fragment: {
      module,
      targets: [{ format: 'rgba8unorm' }],
    },
  });

  const renderPassDescriptor = {
    label: 'our basic canvas renderPass',
    colorAttachments: [
      {
        // view: <- to be filled out when we render
        clearValue: [0.3, 0.3, 0.3, 1],
        loadOp: 'clear',
        storeOp: 'store',
      },
    ],
  };

  const imageUniformBuffer = device.createBuffer({
    size: 4 * 16,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });

  const imageTexture = await createTextureFromImage(
    device,
    'resources/images/david-clode-clown-fish.jpg', /* webgpufundamentals: url */
  );

  const imageSampler = device.createSampler({
    minFilter: 'linear',
    magFilter: 'linear',
  });

  const imageBindGroup = device.createBindGroup({
    layout: pipeline.getBindGroupLayout(0),
    entries: [
      { binding: 0, resource: { buffer: imageUniformBuffer } },
      { binding: 1, resource: imageTexture.createView() },
      { binding: 2, resource: imageSampler },
    ],
  });

  const postProcessModule = device.createShaderModule({
    code: `
      struct VSOutput {
        @builtin(position) position: vec4f,
        @location(0) texcoord: vec2f,
      };

      fn applyLUT(lut: texture_3d<f32>, lutSampler: sampler, color: vec3f) -> vec3f {
        let size = vec3f(textureDimensions(lut));
        return textureSampleLevel(lut, lutSampler, (0.5 + color * (size - 1)) / size, 0).rgb;
      }

      @vertex fn vs(
        @builtin(vertex_index) vertexIndex : u32,
      ) -> VSOutput {
        var pos = array(
          vec2f(-1.0, -1.0),
          vec2f(-1.0,  3.0),
          vec2f( 3.0, -1.0),
        );

        var vsOutput: VSOutput;
        let xy = pos[vertexIndex];
        vsOutput.position = vec4f(xy, 0.0, 1.0);
        vsOutput.texcoord = xy * vec2f(0.5) + vec2f(0.5);
        return vsOutput;
      }

      @group(0) @binding(0) var postTexture2d: texture_2d<f32>;
      @group(0) @binding(1) var postSampler: sampler;
      @group(0) @binding(2) var lutTexture: texture_3d<f32>;
      @group(0) @binding(3) var lutSampler: sampler;

      @fragment fn fs2d(fsInput: VSOutput) -> @location(0) vec4f {
        let color = textureSample(postTexture2d, postSampler, fsInput.texcoord);
        var rgb = color.rgb;
        rgb = applyLUT(lutTexture, lutSampler, rgb);
        return vec4f(rgb, color.a);
      }
    `,
  });

  const postProcessPipeline = device.createRenderPipeline({
    layout: 'auto',
    vertex: { module: postProcessModule },
    fragment: {
      module: postProcessModule,
      targets: [ { format: presentationFormat }],
    },
  });

  const postProcessSampler = device.createSampler({
    minFilter: 'linear',
    magFilter: 'linear',
  });

  const postProcessRenderPassDescriptor = {
    label: 'post process render pass',
    colorAttachments: [
      { loadOp: 'clear', storeOp: 'store' },
    ],
  };

  const lutSamplerNearest = device.createSampler({
    minFilter: 'nearest',
    magFilter: 'nearest',
  });
  const lutSamplerLinear = device.createSampler({
    minFilter: 'linear',
    magFilter: 'linear',
  });

  let renderTarget;
  let renderTargetView;
  let postProcessBindGroup;

  function setupPostProcess(canvasTexture, lutTexture, lutSampler) {
    if (renderTarget?.width !== canvasTexture.width ||
        renderTarget?.height !== canvasTexture.height) {
      renderTarget?.destroy();
      renderTarget = device.createTexture({
        size: canvasTexture,
        format: 'rgba8unorm',
        usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING,
      });
      renderTargetView = renderTarget.createView();
      renderPassDescriptor.colorAttachments[0].view = renderTargetView;
    }

    postProcessBindGroup = device.createBindGroup({
      layout: postProcessPipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: renderTargetView },
        { binding: 1, resource: postProcessSampler },
        { binding: 2, resource: lutTexture.createView() },
        { binding: 3, resource: lutSampler },
      ],
    });
  }

  function postProcess(encoder, srcTexture, dstTexture) {
    postProcessRenderPassDescriptor.colorAttachments[0].view = dstTexture.createView();
    const pass = encoder.beginRenderPass(postProcessRenderPassDescriptor);
    pass.setPipeline(postProcessPipeline);
    pass.setBindGroup(0, postProcessBindGroup);
    pass.draw(3);
    pass.end();
  }

  const settings = {
    lut: 0,
  };

  const gui = new GUI();
  gui.name('Choose LUT or Drag&Drop LUT File(s)');
  gui.onChange(render);

  let lutGUI;
  function updateGUI() {
    if (lutGUI) {
      gui.remove(lutGUI);
    }
    const keyValues = Object.fromEntries(lutTextures.map(({name}, i) => [name, i]));
    lutGUI = gui.add(settings, 'lut', { keyValues });
  }
  updateGUI();

  function render() {
    const canvasTexture = context.getCurrentTexture();
    const { texture, filter } = lutTextures[settings.lut];
    setupPostProcess(canvasTexture, texture, filter ? lutSamplerLinear : lutSamplerNearest);

    // css 'cover'
    const canvasAspect = canvas.clientWidth / canvas.clientHeight;
    const imageAspect = imageTexture.width / imageTexture.height;
    const aspect = canvasAspect / imageAspect;
    const aspectScale = aspect > 1 ? [1, aspect, 1] : [1 / aspect, 1, 1];

    const matrix = mat4.identity();
    mat4.scale(matrix, aspectScale, matrix);
    mat4.scale(matrix, [2, 2, 1], matrix);
    mat4.translate(matrix, [-0.5, -0.5, 1], matrix);

    // Set the uniform values in our JavaScript side Float32Array
    device.queue.writeBuffer(imageUniformBuffer, 0, matrix);

    const encoder = device.createCommandEncoder();
    const pass = encoder.beginRenderPass(renderPassDescriptor);
    pass.setPipeline(pipeline);
    pass.setBindGroup(0, imageBindGroup);
    pass.draw(6);
    pass.end();

    postProcess(encoder, renderTarget, canvasTexture);

    const commandBuffer = encoder.finish();
    device.queue.submit([commandBuffer]);
  }

  const observer = new ResizeObserver(entries => {
    for (const entry of entries) {
      const canvas = entry.target;
      const width = entry.contentBoxSize[0].inlineSize;
      const height = entry.contentBoxSize[0].blockSize;
      canvas.width = Math.max(1, Math.min(width, device.limits.maxTextureDimension2D));
      canvas.height = Math.max(1, Math.min(height, device.limits.maxTextureDimension2D));
    }
    render();
  });
  observer.observe(canvas);

  dragAndDrop.setup({msg: 'Drop LUT File here'});
  dragAndDrop.onDropFile(readLUTFile);

  function ext(s) {
    const period = s.lastIndexOf('.');
    return s.substr(period + 1);
  }

  function readLUTFile(file) {
    const reader = new FileReader();
    reader.onload = (e) => {
      const type = ext(file.name);
      const {size, data, name} = lutParser.lutTo2D3Drgba8(lutParser.parse(e.target.result, type));
      const texture = device.createTexture({
        size: [size, size, size],
        dimension: '3d',
        format: 'rgba8unorm',
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST,
      });
      device.queue.writeTexture(
        { texture },
        data,
        { bytesPerRow: size * 4, rowsPerImage: size },
        [size, size, size],
      );
      lutTextures.push({
        name: (name && name.toLowerCase().trim() !== 'untitled')
          ? name
          : file.name,
        size: size,
        texture,
        filter: true,
      });
      settings.lut = lutTextures.length - 1;
      updateGUI();
      render();
    };

    reader.readAsText(file);
  }
}

function fail(msg) {
  alert(msg);
}

main();
  </script>
</html>
